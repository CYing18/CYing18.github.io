---
title:          Slidechat-A large vision-language assistant for whole-slide pathology image understanding
date:           2025-02-28 00:01:00 +0800
selected:       true
pub:            "CVPR 2025"
# pub_pre:        "Submitted to "
# pub_post:       'Under review.'
pub_last:       ' <span class="badge badge-pill badge-custom badge-secondary">Conference</span>'
pub_date:       "2025"

abstract: >-
  We present SlideChat, the first vision-language assistant capable of understanding gigapixel whole-slide images, exhibiting excellent multimodal conversational capability and response complex instruction across diverse pathology scenarios. To support its development, we created SlideInstruction, the largest instruction-following dataset for WSIs consisting of 4.2K WSI captions and 176K VQA pairs with multiple categories. Furthermore, we propose SlideBench, a multimodal benchmark that incorporates captioning and VQA tasks to assess SlideChat's capabilities in varied clinical settings such as microscopy, diagnosis.
  
cover:          assets/images/covers/SlideChat.png
authors:
  - Ying Chen*
  - Guoan Wang*
  - Yuanfeng Ji†
  - Yanjun Li
  - Jin Ye
  - Tianbin Li
  - Ming Hu
  - Rongshan Yu
  - Yu Qiao
  - Junjun He†
links:
  Paper: https://arxiv.org/abs/2410.11761
  Cite: assets/bibtex/chen2024slidechat.bib
---
